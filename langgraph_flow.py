"""
LangGraphë¥¼ ì‚¬ìš©í•œ Lecture-RAG í”Œë¡œìš° ì‹œê°í™”
"""
from typing import Dict, Any, List, Optional
from typing_extensions import TypedDict
from langgraph.graph import StateGraph, END
from langchain_core.documents import Document
import json

class RAGState(TypedDict):
    """RAG ì²˜ë¦¬ ìƒíƒœë¥¼ ê´€ë¦¬í•˜ëŠ” ìƒíƒœ í´ë˜ìŠ¤"""
    query: str
    documents: List[Document]
    allowed_tokens: Dict[str, Any]
    context: str
    answer: str
    unknown_tokens: List[str]
    needs_retry: bool

def preprocess_query(state: RAGState) -> RAGState:
    """ì‚¬ìš©ì ì§ˆë¬¸ ì „ì²˜ë¦¬"""
    query = state["query"].strip()
    print(f"ğŸ“ Query preprocessing: {query}")
    # queryëŠ” ìˆ˜ì •í•˜ì§€ ì•Šê³  ê·¸ëŒ€ë¡œ ìœ ì§€
    return state

def vector_search(state: RAGState) -> RAGState:
    """ë²¡í„° ê²€ìƒ‰ ìˆ˜í–‰"""
    query = state["query"]
    print(f"ğŸ” Vector search for: {query}")
    
    # ì‹¤ì œë¡œëŠ” VectorStore.search() í˜¸ì¶œ
    # ì—¬ê¸°ì„œëŠ” ì‹œë®¬ë ˆì´ì…˜
    mock_docs = [
        Document(
            page_content="def reverse_list(lst): return lst[::-1]",
            metadata={"kind": "code", "start_line": 10, "end_line": 12}
        )
    ]
    
    # documentsë§Œ ì—…ë°ì´íŠ¸
    return {**state, "documents": mock_docs}  # ì•ˆì „í•œ ì—…ë°ì´íŠ¸

def load_allowed_tokens(state: RAGState) -> RAGState:
    """í—ˆìš©ëœ í† í° ë¡œë“œ"""
    print("ğŸ” Loading allowed tokens...")
    
    # ì‹¤ì œë¡œëŠ” allowed_tokens.jsonì—ì„œ ë¡œë“œ
    mock_tokens = {
        "modules": ["numpy", "pandas", "matplotlib"],
        "symbols": ["list", "dict", "str", "int"]
    }
    
    print(f"âœ… Loaded {len(mock_tokens['modules'])} modules, {len(mock_tokens['symbols'])} symbols")
    return {**state, "allowed_tokens": mock_tokens}

def build_context(state: RAGState) -> RAGState:
    """ê²€ìƒ‰ëœ ë¬¸ì„œë“¤ë¡œ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±"""
    docs = state["documents"]
    
    context_parts = []
    for i, doc in enumerate(docs, 1):
        meta = doc.metadata
        location = f"ë¼ì¸ {meta.get('start_line', '?')}-{meta.get('end_line', '?')}"
        context_parts.append(f"[Chunk {i} | {meta.get('kind')} | {location}]\n{doc.page_content}")
    
    context = "\n\n".join(context_parts)
    
    print(f"ğŸ“„ Built context with {len(docs)} documents")
    return {**state, "context": context}

def generate_answer(state: RAGState) -> RAGState:
    """LLMì„ ì‚¬ìš©í•œ ë‹µë³€ ìƒì„±"""
    query = state["query"]
    context = state["context"]
    
    print(f"ğŸ¤– Generating answer for: {query}")
    
    # ì‹¤ì œë¡œëŠ” LLM í˜¸ì¶œ
    # ì—¬ê¸°ì„œëŠ” ì‹œë®¬ë ˆì´ì…˜
    mock_answer = """
ë¦¬ìŠ¤íŠ¸ë¥¼ ì—­ìˆœìœ¼ë¡œ ì •ë ¬í•˜ëŠ” í•¨ìˆ˜ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:

```python
def reverse_list(lst):
    return lst[::-1]
```

ì´ í•¨ìˆ˜ëŠ” ìŠ¬ë¼ì´ì‹±ì„ ì‚¬ìš©í•˜ì—¬ ë¦¬ìŠ¤íŠ¸ë¥¼ ì—­ìˆœìœ¼ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
"""
    
    print("âœ… Answer generated")
    return {**state, "answer": mock_answer.strip(), "needs_retry": False}

def check_tokens(state: RAGState) -> RAGState:
    """ë‹µë³€ì—ì„œ ë¯¸í—ˆìš© í† í° ê²€ì‚¬"""
    answer = state["answer"]
    allowed = state["allowed_tokens"]
    
    print("ğŸ” Checking for unknown tokens...")
    
    # ì‹¤ì œë¡œëŠ” utils.find_unknown_tokens() í˜¸ì¶œ
    # ì—¬ê¸°ì„œëŠ” ì‹œë®¬ë ˆì´ì…˜
    unknown_tokens = []  # ë¹ˆ ë¦¬ìŠ¤íŠ¸ = ëª¨ë“  í† í°ì´ í—ˆìš©ë¨
    
    if unknown_tokens:
        print(f"âš ï¸ Found {len(unknown_tokens)} unknown tokens: {unknown_tokens}")
    else:
        print("âœ… All tokens are allowed")
    
    return {**state, "unknown_tokens": unknown_tokens, "needs_retry": len(unknown_tokens) > 0}

def retry_with_constraints(state: RAGState) -> RAGState:
    """ì œì•½ì¡°ê±´ê³¼ í•¨ê»˜ ë‹µë³€ ì¬ìƒì„±"""
    query = state["query"]
    unknown_tokens = state["unknown_tokens"]
    
    print(f"ğŸ”„ Retrying with constraints: avoid {unknown_tokens}")
    
    # ì‹¤ì œë¡œëŠ” ì œì•½ì¡°ê±´ì´ í¬í•¨ëœ í”„ë¡¬í”„íŠ¸ë¡œ LLM ì¬í˜¸ì¶œ
    constrained_answer = state["answer"] + "\n\n(ì¬ìƒì„±ë¨: ë¯¸í—ˆìš© í† í° ì œê±°)"
    
    print("âœ… Answer regenerated with constraints")
    return {**state, "answer": constrained_answer, "unknown_tokens": [], "needs_retry": False}

def should_retry(state: RAGState) -> str:
    """ì¬ì‹œë„ê°€ í•„ìš”í•œì§€ íŒë‹¨"""
    if state["needs_retry"]:
        return "retry"
    return "end"

def create_rag_graph():
    """RAG í”Œë¡œìš° ê·¸ë˜í”„ ìƒì„±"""
    
    # ê·¸ë˜í”„ ìƒì„±
    workflow = StateGraph(RAGState)
    
    # ë…¸ë“œ ì¶”ê°€
    workflow.add_node("preprocess_query", preprocess_query)
    workflow.add_node("vector_search", vector_search)
    workflow.add_node("load_allowed_tokens", load_allowed_tokens)
    workflow.add_node("build_context", build_context)
    workflow.add_node("generate_answer", generate_answer)
    workflow.add_node("check_tokens", check_tokens)
    workflow.add_node("retry_with_constraints", retry_with_constraints)
    
    # ì—£ì§€ ì¶”ê°€ (í”Œë¡œìš° ì •ì˜) - ìˆœì°¨ì ìœ¼ë¡œ ë³€ê²½
    workflow.set_entry_point("preprocess_query")
    
    # ìˆœì°¨ ì²˜ë¦¬ë¡œ ë³€ê²½ (ë™ì‹œ ì—…ë°ì´íŠ¸ ë¬¸ì œ í•´ê²°)
    workflow.add_edge("preprocess_query", "vector_search")
    workflow.add_edge("vector_search", "load_allowed_tokens")
    workflow.add_edge("load_allowed_tokens", "build_context")
    workflow.add_edge("build_context", "generate_answer")
    workflow.add_edge("generate_answer", "check_tokens")
    
    # ì¡°ê±´ë¶€ ë¼ìš°íŒ…
    workflow.add_conditional_edges(
        "check_tokens",
        should_retry,
        {
            "retry": "retry_with_constraints",
            "end": END
        }
    )
    
    # ì¬ì‹œë„ í›„ ë‹¤ì‹œ í† í° ê²€ì‚¬
    workflow.add_edge("retry_with_constraints", "check_tokens")
    
    return workflow.compile()

def visualize_graph():
    """ê·¸ë˜í”„ ì‹œê°í™”"""
    print("ğŸ¨ Creating graph visualizations...")
    
    # ê·¸ë˜í”„ ìƒì„±
    app = create_rag_graph()
    
    try:
        # 1. Mermaid ë‹¤ì´ì–´ê·¸ë¨ìœ¼ë¡œ ì¶œë ¥
        mermaid_code = app.get_graph().draw_mermaid()
        with open("rag_flow_mermaid.md", "w", encoding="utf-8") as f:
            f.write("# RAG Flow Diagram\n\n")
            f.write("```mermaid\n")
            f.write(mermaid_code)
            f.write("\n```")
        print("âœ… Mermaid diagram saved to: rag_flow_mermaid.md")
        
        # 2. PNG ì´ë¯¸ì§€ë¡œ ì¶œë ¥ (graphviz í•„ìš”)
        try:
            img = app.get_graph().draw_mermaid_png()
            with open("rag_flow.png", "wb") as f:
                f.write(img)
            print("âœ… PNG diagram saved to: rag_flow.png")
        except Exception as e:
            print(f"âš ï¸ PNG generation failed (install graphviz): {e}")
            
        # 3. ASCII ë‹¤ì´ì–´ê·¸ë¨ ì¶œë ¥
        print("\nğŸ“Š Graph Structure (ASCII):")
        print(app.get_graph().draw_ascii())
        
    except Exception as e:
        print(f"âŒ Visualization failed: {e}")
        print("Install required packages: pip install 'langgraph[draw]'")

def run_rag_demo():
    """RAG ë°ëª¨ ì‹¤í–‰"""
    print("ğŸš€ Starting Lecture-RAG LangGraph Demo")
    print("=" * 50)
    
    # ê·¸ë˜í”„ ìƒì„±
    app = create_rag_graph()
    
    # ì‹œê°í™”
    visualize_graph()
    print("\n" + "=" * 50)
    
    # ì´ˆê¸° ìƒíƒœ
    initial_state = {
        "query": "ë¦¬ìŠ¤íŠ¸ë¥¼ ì—­ìˆœìœ¼ë¡œ ì •ë ¬í•˜ëŠ” í•¨ìˆ˜ ë§Œë“¤ì–´ì¤˜",
        "documents": [],
        "allowed_tokens": {},
        "context": "",
        "answer": "",
        "unknown_tokens": [],
        "needs_retry": False
    }
    
    # ì‹¤í–‰
    print("ğŸ¯ Processing query:", initial_state["query"])
    print("-" * 50)
    
    result = app.invoke(initial_state)
    
    print("-" * 50)
    print("ğŸ‰ Final Result:")
    print(result["answer"])
    
    return result

if __name__ == "__main__":
    # íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì•ˆë‚´
    try:
        from langgraph.graph import StateGraph, END
        run_rag_demo()
    except ImportError:
        print("âŒ LangGraphê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        print("ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ ì„¤ì¹˜í•˜ì„¸ìš”:")
        print("pip install langgraph")