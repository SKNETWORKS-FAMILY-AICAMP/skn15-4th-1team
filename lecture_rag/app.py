"""
Streamlit ê¸°ë°˜ Lecture-RAG ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜
ê°•ì˜ë¡ì„ ì¸ë±ì‹±í•˜ê³  ì§ˆì˜ì‘ë‹µì„ ì œê³µí•˜ëŠ” ì›¹ ì¸í„°í˜ì´ìŠ¤
"""
from __future__ import annotations
import re
from pathlib import Path
from typing import Optional, List, Dict, Any

import streamlit as st

from .config import Config
from .vector_store import VectorStore
from .llm_handler import LLMHandler
from .google_drive import GoogleDriveClient, is_google_drive_available


class LectureRAGApp:
    """Lecture-RAG"""
    
    def __init__(self):
        self.config = Config.from_env()
        self._setup_page()
        self._init_session_state()
    
    def _setup_page(self):
        """í˜ì´ì§€ ê¸°ë³¸ ì„¤ì •"""
        st.set_page_config(
            page_title="Lecture-RAG", 
            page_icon="ğŸ“š", 
            layout="wide"
        )
        st.title("Lecture-RAG")
        
        # ì±„íŒ… ìŠ¤íƒ€ì¼ CSS ì¶”ê°€
        st.markdown("""
        <style>
        .chat-container {
            max-width: 800px;
            margin: 0;
            padding: 20px 0;
        }
        
        /* ì‚¬ìš©ì ë©”ì‹œì§€ (ì˜¤ë¥¸ìª½) */
        .user-message-container {
            display: flex;
            justify-content: flex-end;
            margin: 15px 0;
        }
        .user-message {
            background: linear-gradient(135deg, #4f46e5 0%, #7c3aed 100%);
            color: white;
            padding: 12px 16px;
            border-radius: 18px 18px 4px 18px;
            max-width: 70%;
            box-shadow: 0 2px 12px rgba(79, 70, 229, 0.3);
            margin-left: 20px;
        }
        .user-label {
            font-size: 0.75em;
            opacity: 0.8;
            margin-bottom: 4px;
            text-align: right;
        }
        .user-content {
            font-size: 15px;
            line-height: 1.4;
            word-wrap: break-word;
        }
        
        /* AI ë©”ì‹œì§€ (ì™¼ìª½) */
        .ai-message-container {
            display: flex;
            justify-content: flex-start;
            margin: 15px 0;
            padding-left: 0;
        }
        .ai-avatar {
            width: 40px;
            height: 40px;
            background: linear-gradient(135deg, #10b981 0%, #059669 100%);
            border-radius: 50%;
            display: flex;
            align-items: center;
            justify-content: center;
            color: white;
            font-weight: bold;
            font-size: 14px;
            margin-right: 12px;
            flex-shrink: 0;
        }
        .ai-message {
            background: #ffffff;
            border: 1px solid #e5e7eb;
            padding: 14px 18px;
            border-radius: 18px 18px 18px 4px;
            max-width: 70%;
            box-shadow: 0 2px 8px rgba(0, 0, 0, 0.06);
            position: relative;
        }
        .ai-label {
            font-size: 0.75em;
            color: #10b981;
            font-weight: 600;
            margin-bottom: 6px;
        }
        .ai-content {
            font-size: 15px;
            line-height: 1.5;
            color: #374151;
            word-wrap: break-word;
        }
        .click-hint {
            font-size: 0.7em;
            color: #9ca3af;
            margin-top: 8px;
            font-style: italic;
        }
        
        /* ë²„íŠ¼ ìŠ¤íƒ€ì¼ ê°œì„  */
        .stButton > button {
            width: 100% !important;
            background: transparent !important;
            border: 2px solid #000000 !important;
            border-radius: 18px !important;
            padding: 0 !important;
            margin: 0 !important;
            text-align: left !important;
            color: #000000 !important;
        }
        .stButton > button:hover {
            background: transparent !important;
            border-color: #000000 !important;
        }
        .ai-message {
            background: #ffffff;
            border: 2px solid #000000;
            padding: 14px 18px;
            border-radius: 18px 18px 18px 4px;
            max-width: 70%;
            box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
            position: relative;
        }
        .ai-message:hover {
            border-color: #000000;
            box-shadow: 0 4px 16px rgba(0, 0, 0, 0.2);
            cursor: pointer;
            transition: all 0.2s ease;
        }
        .ai-content {
            font-size: 15px;
            line-height: 1.5;
            color: #000000;
            word-wrap: break-word;
        }
        
        /* ì…ë ¥ì°½ ìŠ¤íƒ€ì¼ */
        .stTextInput > div > div > input {
            border-radius: 25px;
            border: 2px solid #e5e7eb;
            padding: 12px 20px;
        }
        .stTextInput > div > div > input:focus {
            border-color: #4f46e5;
            box-shadow: 0 0 0 3px rgba(79, 70, 229, 0.1);
        }
        </style>
        """, unsafe_allow_html=True)
    
    def _render_sidebar(self) -> tuple[VectorStore, str, float]:
        """ì‚¬ì´ë“œë°” ë Œë”ë§"""
        with st.sidebar:
            st.header("ì„¤ì •")
            
            # ë²¡í„° ìŠ¤í† ì–´ ë””ë ‰í† ë¦¬ ì„¤ì •
            store_dir_str = st.text_input(
                "FAISS ì €ì¥ ë””ë ‰í„°ë¦¬", 
                value=self.config.default_store_dir
            )
            store_dir = Path(store_dir_str)
            vector_store = VectorStore(store_dir)
            
            # LLM ëª¨ë¸ ì„¤ì •
            available_models = [
                "gpt-3.5-turbo",
                "gpt-4o-mini",
                "gpt-4o",
                "claude-3-haiku-20240307",
                "claude-3-sonnet-20240229",
                "claude-3-opus-20240229",
                "gemini-1.5-flash",
                "gemini-1.5-pro"
            ]
            
            # í˜„ì¬ ì„¤ì •ëœ ëª¨ë¸ì´ ëª©ë¡ì— ì—†ìœ¼ë©´ ì¶”ê°€
            if self.config.model_name not in available_models:
                available_models.insert(0, self.config.model_name)
            
            model = st.selectbox(
                "LLM ëª¨ë¸", 
                options=available_models,
                index=available_models.index(self.config.model_name)
            )
            temp = st.slider(
                "Temperature", 
                0.0, 1.0, 
                self.config.temperature, 
                0.05
            )
            
            st.caption("â€» OpenAI ì‚¬ìš© ì‹œ í™˜ê²½ë³€ìˆ˜ OPENAI_API_KEYê°€ í•„ìš”í•©ë‹ˆë‹¤.")
            
            # ì¸ë±ì‹± ì„¹ì…˜
            self._render_indexing_section(vector_store, model, temp)
            
            return vector_store, model, temp
    
    def _init_session_state(self):
        """ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”"""
        if "messages" not in st.session_state:
            st.session_state.messages = []
        if "detailed_view" not in st.session_state:
            st.session_state.detailed_view = None  # ìƒì„¸ ë³´ê¸°í•  ë©”ì‹œì§€ ID
        if "message_counter" not in st.session_state:
            st.session_state.message_counter = 0
    
    def _render_indexing_section(
        self, 
        vector_store: VectorStore, 
        model: str, 
        temp: float
    ):
        """ì¸ë±ì‹± ì„¹ì…˜ ë Œë”ë§"""
        st.divider()
        st.subheader("ì¸ë±ì‹±")
        
        # Google Driveì—ì„œ ê°€ì ¸ì˜¤ê¸° ë²„íŠ¼ (ìƒë‹¨ì— ë°°ì¹˜)
        if is_google_drive_available():
            if st.button("ğŸ“¥ êµ¬ê¸€ë“œë¼ì´ë¸Œì—ì„œ ê°•ì˜ë¡ ê°€ì ¸ì˜¤ê¸°", 
                        help="SKN15 í´ë”ì˜ ê°•ì˜ë¡.txtë¥¼ ìë™ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤",
                        use_container_width=True):
                self._handle_google_drive_download()
            st.divider()  # êµ¬ë¶„ì„  ì¶”ê°€
        else:
            st.info("ğŸ’¡ Google Drive ì—°ë™ì„ ìœ„í•´ `pip install google-api-python-client google-auth-oauthlib` ì„¤ì¹˜")
            st.divider()
        
        # íŒŒì¼ ì—…ë¡œë“œ ë° ê²½ë¡œ ì…ë ¥
        st.write("**ë˜ëŠ” ì§ì ‘ ì—…ë¡œë“œ:**")
        upload = st.file_uploader(
            "ê°•ì˜ë¡ íŒŒì¼ ì—…ë¡œë“œ(.txt, .md ë“±)", 
            type=["txt", "md", "py", "mdx"], 
            accept_multiple_files=False
        )
        
        st.write("**ë˜ëŠ” ë¡œì»¬ íŒŒì¼ ê²½ë¡œ:**")
        manual_path = st.text_input("íŒŒì¼ ê²½ë¡œë¥¼ ì…ë ¥í•˜ì„¸ìš”", value="ê°•ì˜ë¡.txt")

        if st.button("ì¸ë±ì‹± ì‹¤í–‰", type="primary"):
            self._handle_indexing(vector_store, upload, manual_path, model, temp)
    
    def _handle_indexing(
        self, 
        vector_store: VectorStore, 
        upload: Optional[st.runtime.uploaded_file_manager.UploadedFile], 
        manual_path: str, 
        model: str, 
        temp: float
    ):
        """ì¸ë±ì‹± ì²˜ë¦¬"""
        # íŒŒì¼ ê²½ë¡œ ê²°ì •
        if upload is not None:
            tmp_path = vector_store.store_dir / "uploaded_lecture.txt"
            tmp_path.write_bytes(upload.read())
            path_to_index = tmp_path
        else:
            path_to_index = Path(manual_path)

        if not path_to_index.exists():
            st.error(f"ê°•ì˜ë¡ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {path_to_index}")
            return
        
        # í™˜ê²½ ì„¤ì • ì—…ë°ì´íŠ¸
        config = Config(model_name=model, temperature=temp)
        config.to_env()
        
        # ì¸ë±ì‹± ì‹¤í–‰
        with st.spinner("ì¸ë±ì‹± ì¤‘..."):
            n_docs, allowed = vector_store.index_document(path_to_index)
        
        st.success(f"ì¸ë±ì‹± ì™„ë£Œ! ë¬¸ì„œ ì¡°ê° {n_docs}ê°œ ìƒì„±")
        with st.expander("í—ˆìš© í† í°(ëª¨ë“ˆ/ì‹¬ë³¼) ë³´ê¸°"):
            st.json(allowed)
    
    def _handle_google_drive_download(self):
        """Google Driveì—ì„œ ê°•ì˜ë¡ ë‹¤ìš´ë¡œë“œ ì²˜ë¦¬"""
        try:
            with st.spinner("Google Drive ì—°ê²° ì¤‘..."):
                drive_client = GoogleDriveClient()
                
                # ì¸ì¦ í™•ì¸
                auth_result = drive_client.authenticate()
                
                if auth_result is True:
                    # ì´ë¯¸ ì¸ì¦ë¨ - ë°”ë¡œ ë‹¤ìš´ë¡œë“œ
                    with st.spinner("SKN15/ê°•ì˜ë¡.txt ë‹¤ìš´ë¡œë“œ ì¤‘..."):
                        success = drive_client.download_lecture_file(Path("ê°•ì˜ë¡.txt"))
                        
                    if success:
                        st.success("âœ… êµ¬ê¸€ë“œë¼ì´ë¸Œì—ì„œ ê°•ì˜ë¡.txtë¥¼ ì„±ê³µì ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œí–ˆìŠµë‹ˆë‹¤!")
                        st.info("ì´ì œ 'ì¸ë±ì‹± ì‹¤í–‰' ë²„íŠ¼ì„ í´ë¦­í•˜ì—¬ ì¸ë±ì‹±ì„ ì§„í–‰í•˜ì„¸ìš”.")
                    else:
                        st.error("âŒ íŒŒì¼ ë‹¤ìš´ë¡œë“œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                        
                elif isinstance(auth_result, tuple):
                    # ì¸ì¦ í•„ìš”
                    auth_success, auth_url = auth_result
                    
                    st.warning("ğŸ” Google Drive ì¸ì¦ì´ í•„ìš”í•©ë‹ˆë‹¤.")
                    st.markdown(f"**1ë‹¨ê³„:** [ì—¬ê¸°ë¥¼ í´ë¦­í•˜ì—¬ ì¸ì¦í•˜ì„¸ìš”]({auth_url})")
                    
                    with st.expander("ğŸ“‹ ì¸ì¦ ê³¼ì • ì•ˆë‚´", expanded=True):
                        st.write("1. ìœ„ ë§í¬ í´ë¦­ â†’ Google ë¡œê·¸ì¸")
                        st.write("2. ì•± ê¶Œí•œ ìŠ¹ì¸")
                        st.write("3. âœ¨ **ë¸Œë¼ìš°ì €ì— í‘œì‹œë˜ëŠ” ì½”ë“œë¥¼ ë³µì‚¬**")
                        st.write("4. ì•„ë˜ ì…ë ¥ë€ì— ë¶™ì—¬ë„£ê¸°")
                        st.code("ì˜ˆì‹œ: 4/0AZEOvhX-abcd1234efgh5678...")
                    
                    # ì¸ì¦ ì½”ë“œ ì…ë ¥ë€
                    auth_code = st.text_input(
                        "**2ë‹¨ê³„:** ì¸ì¦ ì½”ë“œë¥¼ ì—¬ê¸°ì— ë¶™ì—¬ë„£ìœ¼ì„¸ìš”:",
                        help="ë¸Œë¼ìš°ì €ì— 'Please copy this code...' ë¼ê³  ë‚˜ì˜¤ëŠ” ê¸´ ì½”ë“œë¥¼ ë³µì‚¬í•´ì„œ ë¶™ì—¬ë„£ìœ¼ì„¸ìš”",
                        placeholder="4/0AZEOvhX-..."
                    )
                    
                    if auth_code and st.button("ì¸ì¦ ì™„ë£Œ"):
                        try:
                            if drive_client.complete_auth(auth_code):
                                st.success("âœ… ì¸ì¦ ì™„ë£Œ! ë‹¤ì‹œ ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”.")
                                st.rerun()
                            else:
                                st.error("âŒ ì¸ì¦ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                        except Exception as e:
                            st.error(f"âŒ ì¸ì¦ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
                            
        except Exception as e:
            st.error(f"âŒ Google Drive ì—°ê²° ì‹¤íŒ¨: {str(e)}")
            st.info("ğŸ’¡ í´ë¼ì´ì–¸íŠ¸ IDê°€ ì˜¬ë°”ë¥´ê²Œ ì„¤ì •ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
    
    def _render_qa_section(
        self, 
        vector_store: VectorStore, 
        model: str, 
        temp: float
    ):
        """ì§ˆì˜ì‘ë‹µ ì„¹ì…˜ ë Œë”ë§"""
        st.divider()
        
        # ìƒì„¸ ë³´ê¸°ê°€ í™œì„±í™”ëœ ê²½ìš° ìƒì„¸ í™”ë©´ ë Œë”ë§
        if st.session_state.detailed_view is not None:
            self._render_detailed_view()
            return
        
        # ì±„íŒ…í˜• ì¸í„°í˜ì´ìŠ¤ ë Œë”ë§
        self._render_chat_interface(vector_store, model, temp)
    
    def _render_chat_interface(
        self, 
        vector_store: VectorStore, 
        model: str, 
        temp: float
    ):
        """ì±„íŒ…í˜• ì¸í„°í˜ì´ìŠ¤ ë Œë”ë§"""
        st.subheader("ğŸ’¬ ì±„íŒ…")
        
        # ì˜µì…˜ ì„¤ì •
        with st.expander("âš™ï¸ ì˜µì…˜ ì„¤ì •", expanded=False):
            topk = st.slider(
                "Top-K ë¬¸ì„œ", 
                min_value=self.config.min_top_k, 
                max_value=self.config.max_top_k, 
                value=self.config.default_top_k, 
                step=1
            )
            st.session_state.topk = topk
        
        # ë©”ì‹œì§€ íˆìŠ¤í† ë¦¬ í‘œì‹œ
        if st.session_state.messages:
            st.markdown('<div class="chat-container">', unsafe_allow_html=True)
            for message in st.session_state.messages:
                self._render_message(message)
            st.markdown('</div>', unsafe_allow_html=True)
        else:
            st.markdown(
                '''
                <div style="text-align: center; padding: 40px 0; color: #9ca3af;">
                    <h3>ì•ˆë…•í•˜ì„¸ìš”! AIì›…ì´ì—ìš” ğŸ¤–</h3>
                    <p>ê°•ì˜ë¡ì— ëŒ€í•´ ê¶ê¸ˆí•œ ê²ƒì„ ë¬¼ì–´ë³´ì„¸ìš”!</p>
                </div>
                ''',
                unsafe_allow_html=True
            )
        
        # ì§ˆë¬¸ ì…ë ¥
        query = st.text_input(
            "", 
            placeholder="ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”",
            key=f"chat_input_{st.session_state.message_counter}"
        )
        
        # ì „ì†¡ ë²„íŠ¼
        col1, col2, col3 = st.columns([1, 1, 4])
        with col1:
            send_button = st.button("ğŸ“¤ ì „ì†¡", type="primary")
        with col2:
            clear_button = st.button("ğŸ—‘ï¸ ì´ˆê¸°í™”")
        
        if clear_button:
            st.session_state.messages = []
            st.session_state.message_counter = 0
            st.rerun()
        
        if send_button and query.strip():
            self._handle_chat_qa(vector_store, query, model, temp)
    
    def _handle_qa(
        self, 
        vector_store: VectorStore, 
        query: str, 
        topk: int, 
        model: str, 
        temp: float
    ):
        """ì§ˆì˜ì‘ë‹µ ì²˜ë¦¬"""
        if not query.strip():
            st.warning("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”.")
            return
        
        # í™˜ê²½ ì„¤ì • ì—…ë°ì´íŠ¸
        config = Config(model_name=model, temperature=temp)
        config.to_env()
        
        # ë¬¸ì„œ ê²€ìƒ‰
        with st.spinner("ê²€ìƒ‰ ì¤‘..."):
            try:
                docs, allowed = vector_store.search(query, k=topk)
            except Exception as e:
                st.error(f"ì¸ë±ìŠ¤ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ì¸ë±ì‹±ì„ ìˆ˜í–‰í•˜ì„¸ìš”. ìƒì„¸: {e}")
                return

        if not docs:
            st.error("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ì‚¬ì´ë“œë°”ì—ì„œ ì¸ë±ì‹±ì„ ë¨¼ì € ìˆ˜í–‰í–ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
            return
        
        
        # LLM ë‹µë³€ ìƒì„±
        llm_handler = LLMHandler(config)
        with st.spinner("LLM ì‘ë‹µ ìƒì„± ì¤‘..."):
            answer = llm_handler.generate_answer(query, docs, allowed)
        
        # ë¯¸í—ˆìš© í† í° ë¡œê·¸ (ë””ë²„ê¹…ìš©)
        unknown_tokens = llm_handler._check_unknown_tokens(answer, allowed)
        if unknown_tokens:
            with st.expander("ë¯¸í—ˆìš© í† í° ê°ì§€ ë¡œê·¸", expanded=False):
                st.write(", ".join(sorted(set(unknown_tokens))))
        
        # ê²°ê³¼ í‘œì‹œ
        st.subheader("ë‹µë³€")
        st.markdown(answer)
        
        # ê±°ì ˆ ì‘ë‹µì¸ì§€ í™•ì¸í•˜ì—¬ ìŠ¤ë‹ˆí« í‘œì‹œ ì—¬ë¶€ ê²°ì •
        rejection_keywords = [
            "ê°•ì˜ë¡ì—ì„œ ë‹¤ë£¨ì§€ ì•Šì€ ì£¼ì œ",
            "ê°•ì˜ë¡ì— ì—†ëŠ” ë‚´ìš©",
            "ì œê³µëœ ì»¨í…ìŠ¤íŠ¸ì—ì„œ ì°¾ì„ ìˆ˜ ì—†",
            "ê°•ì˜ë¡ì—ì„œ ê´€ë ¨ ë‚´ìš©ì„ ì°¾ì„ ìˆ˜ ì—†"
        ]
        
        is_rejection = any(keyword in answer for keyword in rejection_keywords)
        
        if not is_rejection:
            self._render_evidence_snippets(docs)
        else:
            st.info("ğŸ’¡ ê´€ë ¨ ë‚´ìš©ì´ ê°•ì˜ë¡ì— ì—†ì–´ ê·¼ê±° ìŠ¤ë‹ˆí«ì„ í‘œì‹œí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
    
    def _render_evidence_snippets(self, docs):
        """ê·¼ê±° ìŠ¤ë‹ˆí«ë“¤ì„ ë Œë”ë§"""
        st.subheader("ê·¼ê±° ìŠ¤ë‹ˆí«")
        
        for i, d in enumerate(docs, 1):
            meta = d.metadata
            location_info = f"ë¼ì¸ {meta.get('start_line', '?')}-{meta.get('end_line', '?')}"
            first_line = meta.get('first_line_preview', '')
            
            # ë‚ ì§œ ê¸°ë°˜ ì²­í‚¹ì¸ ê²½ìš° ë‚ ì§œ í‘œì‹œ
            if meta.get('kind') == 'lecture_date':
                date = meta.get('date', 'Unknown')
                title = f"ğŸ“… {date} | {location_info} | {first_line}"
            else:
                title = f"Chunk {i} | {meta.get('kind')} | {location_info} | ì‹œì‘: {first_line}"
            
            with st.expander(title, expanded=False):
                # ìœ„ì¹˜ ì •ë³´ í‘œì‹œ
                if meta.get('kind') == 'lecture_date':
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.caption(f"ğŸ“… ê°•ì˜ì¼: {meta.get('date', 'Unknown')}")
                    with col2:
                        st.caption(f"ğŸ“ ìœ„ì¹˜: {location_info}")
                    with col3:
                        st.caption(f"ğŸ“ ì¤„ ìˆ˜: {meta.get('line_count', '?')}ì¤„")
                else:
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.caption(f"ğŸ“ ìœ„ì¹˜: {location_info}")
                    with col2:
                        st.caption(f"ğŸ“ ì¤„ ìˆ˜: {meta.get('line_count', '?')}ì¤„")
                    with col3:
                        st.caption(f"ğŸ·ï¸ íƒ€ì…: {meta.get('kind')}")
                
                # ë‚´ìš© í‘œì‹œ
                snippet = d.page_content
                language = "python" if meta.get('kind') == 'code' else "text"
                st.code(snippet, language=language)
                
                # ì›ë³¸ íŒŒì¼ì—ì„œ ì°¾ëŠ” ë°©ë²• ì•ˆë‚´
                st.info(f"ğŸ’¡ ì›ë³¸ì—ì„œ ì°¾ê¸°: '{meta.get('first_line_preview', '')}' ê²€ìƒ‰í•˜ì—¬ {location_info} í™•ì¸")
    
    def _render_message(self, message: Dict[str, Any]):
        """ê°œë³„ ë©”ì‹œì§€ ë Œë”ë§"""
        if message["role"] == "user":
            # ì‚¬ìš©ì ë©”ì‹œì§€ (ì˜¤ë¥¸ìª½)
            st.markdown(
                f'''
                <div class="user-message-container">
                    <div class="user-message">
                        <div class="user-label">You</div>
                        <div class="user-content">{message["content"]}</div>
                    </div>
                </div>
                ''',
                unsafe_allow_html=True
            )
        else:  # assistant
            # ìš”ì•½ ë‹µë³€ ë¹„ê³µì¸ì§€ í™•ì¸
            has_summary = "summary" in message and message["summary"].strip()
            
            if has_summary:
                # AI ë©”ì‹œì§€ (ì™¼ìª½) - í´ë¦­ ê°€ëŠ¥í•œ ë²„íŠ¼ìœ¼ë¡œ í‘œì‹œ
                col1, col2 = st.columns([0.5, 11])
                
                with col1:
                    st.markdown(
                        '<div class="ai-avatar">ì›…</div>',
                        unsafe_allow_html=True
                    )
                
                with col2:
                    if st.button(
                        f"**AIì›…**\n\n{message['summary']}\n\n*ğŸ“‹ í´ë¦­í•˜ì—¬ ìƒì„¸ ë‹µë³€ ë° ê·¼ê±° ìŠ¤ë‹ˆí« ë³´ê¸°*",
                        key=f"message_{message['id']}",
                        help="í´ë¦­í•˜ì—¬ ìƒì„¸ ë‹µë³€ ë³´ê¸°",
                        use_container_width=True
                    ):
                        st.session_state.detailed_view = message["id"]
                        st.rerun()
            else:
                # ìš”ì•½ì´ ì—†ìœ¼ë©´ ì „ì²´ ë‹µë³€ í‘œì‹œ
                col1, col2 = st.columns([0.5, 11])
                
                with col1:
                    st.markdown(
                        '<div class="ai-avatar">ì›…</div>',
                        unsafe_allow_html=True
                    )
                
                with col2:
                    st.markdown(
                        f'''
                        <div class="ai-message">
                            <div class="ai-label">AIì›…</div>
                            <div class="ai-content">{message["content"]}</div>
                        </div>
                        ''',
                        unsafe_allow_html=True
                    )
    
    
    def _handle_chat_qa(
        self, 
        vector_store: VectorStore, 
        query: str, 
        model: str, 
        temp: float
    ):
        """ì±„íŒ…í˜• ì§ˆì˜ì‘ë‹µ ì²˜ë¦¬"""
        # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
        user_message = {
            "role": "user",
            "content": query,
            "id": st.session_state.message_counter
        }
        st.session_state.messages.append(user_message)
        st.session_state.message_counter += 1
        
        # ì…ë ¥ í•„ë“œëŠ” ìë™ìœ¼ë¡œ ì´ˆê¸°í™”ë¨ (ì§ì ‘ ìˆ˜ì •í•˜ì§€ ì•ŠìŒ)
        
        # ë‹µë³€ ìƒì„±
        topk = st.session_state.get('topk', self.config.default_top_k)
        
        # ë¡œë”© ë©”ì‹œì§€ ì„ì‹œ í‘œì‹œ
        with st.empty():
            col1, col2 = st.columns([0.5, 11])
            with col1:
                st.markdown('<div class="ai-avatar">ì›…</div>', unsafe_allow_html=True)
            with col2:
                with st.spinner("AIì›…ì´ ë‹µë³€ì„ ìƒì„±í•˜ê³  ìˆì–´ìš”..."):
                    try:
                        # ê¸°ì¡´ QA ë¡œì§ ì‚¬ìš©
                        config = Config(model_name=model, temperature=temp)
                        config.to_env()
                        
                        # ë¬¸ì„œ ê²€ìƒ‰
                        docs, allowed = vector_store.search(query, k=topk)
                        
                        if not docs:
                            assistant_message = {
                                "role": "assistant",
                                "content": "ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ì¸ë±ì‹±ì„ ë¨¼ì € ìˆ˜í–‰í•´ì£¼ì„¸ìš”.",
                                "id": st.session_state.message_counter,
                                "summary": ""
                            }
                        else:
                            # LLM ë‹µë³€ ìƒì„±
                            llm_handler = LLMHandler(config)
                            full_answer = llm_handler.generate_answer(query, docs, allowed)
                            
                            # ìš”ì•½ ë‹µë³€ ìƒì„±
                            summary_answer = self._generate_summary_answer(llm_handler, query, full_answer)
                            
                            assistant_message = {
                                "role": "assistant",
                                "content": full_answer,
                                "summary": summary_answer,
                                "id": st.session_state.message_counter,
                                "query": query,
                                "docs": docs,
                                "allowed": allowed,
                                "unknown_tokens": llm_handler._check_unknown_tokens(full_answer, allowed)
                            }
                        
                        # ë‹µë³€ ë©”ì‹œì§€ ì¶”ê°€
                        st.session_state.messages.append(assistant_message)
                        st.session_state.message_counter += 1
                        
                    except Exception as e:
                        error_message = {
                            "role": "assistant",
                            "content": f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
                            "id": st.session_state.message_counter,
                            "summary": ""
                        }
                        st.session_state.messages.append(error_message)
                        st.session_state.message_counter += 1
        
        st.rerun()
    
    def _generate_summary_answer(self, llm_handler: LLMHandler, query: str, full_answer: str) -> str:
        """ìš”ì•½ ë‹µë³€ ìƒì„±"""
        try:
            llm = llm_handler._create_llm()
            summary_prompt = f"""
            ë‹¤ìŒ ì§ˆë¬¸ê³¼ ë‹µë³€ì„ ë°”íƒ•ìœ¼ë¡œ 2-3ë¬¸ì¥ìœ¼ë¡œ ê°„ë‹¨íˆ ìš”ì•½í•´ì£¼ì„¸ìš”.
            
            ì§ˆë¬¸: {query}
            
            ì›ë³¸ ë‹µë³€:
            {full_answer}
            
            ìš”ì•½ (ê°„ë‹¨í•˜ê³  í•µì‹¬ë¡œìš´ 2-3ë¬¸ì¥):
            """
            
            response = llm.invoke([("user", summary_prompt)])
            return response.content.strip()
        except:
            # ìš”ì•½ ìƒì„± ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ë©”ì‹œì§€
            return "ë‹µë³€ì´ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤. í´ë¦­í•˜ì—¬ ìƒì„¸ ë‹µë³€ì„ í™•ì¸í•˜ì„¸ìš”."
    
    def _render_detailed_view(self):
        """ìƒì„¸ ë³´ê¸° í™”ë©´ ë Œë”ë§"""
        message_id = st.session_state.detailed_view
        
        # í•´ë‹¹ ë©”ì‹œì§€ ì°¾ê¸°
        target_message = None
        for msg in st.session_state.messages:
            if msg.get("id") == message_id:
                target_message = msg
                break
        
        if not target_message:
            st.error("ë©”ì‹œì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            st.session_state.detailed_view = None
            st.rerun()
            return
        
        # ë’¤ë¡œê°€ê¸° ë²„íŠ¼
        if st.button("â¬…ï¸ ì±„íŒ…ìœ¼ë¡œ ëŒì•„ê°€ê¸°"):
            st.session_state.detailed_view = None
            st.rerun()
            return
        
        st.divider()
        
        # ì§ˆë¬¸ í‘œì‹œ
        st.subheader("ğŸ™‹â€â™‚ï¸ ì§ˆë¬¸")
        st.markdown(f"**{target_message.get('query', 'ì§ˆë¬¸ ì •ë³´ ì—†ìŒ')}**")
        
        # ìƒì„¸ ë‹µë³€ í‘œì‹œ
        st.subheader("ğŸ¤– ìƒì„¸ ë‹µë³€")
        st.markdown(target_message.get("content", "ë‹µë³€ ì •ë³´ ì—†ìŒ"))
        
        # ë¯¸í—ˆìš© í† í° ë¡œê·¸
        unknown_tokens = target_message.get("unknown_tokens", [])
        if unknown_tokens:
            with st.expander("ë¯¸í—ˆìš© í† í° ê°ì§€ ë¡œê·¸", expanded=False):
                st.write(", ".join(sorted(set(unknown_tokens))))
        
        # ê·¼ê±° ìŠ¤ë‹ˆí« í‘œì‹œ
        docs = target_message.get("docs", [])
        if docs:
            # ê±°ì ˆ ì‘ë‹µì¸ì§€ í™•ì¸
            content = target_message.get("content", "")
            rejection_keywords = [
                "ê°•ì˜ë¡ì—ì„œ ë‹¤ë£¨ì§€ ì•Šì€ ì£¼ì œ",
                "ê°•ì˜ë¡ì— ì—†ëŠ” ë‚´ìš©",
                "ì œê³µëœ ì»¨í…ìŠ¤íŠ¸ì—ì„œ ì°¾ì„ ìˆ˜ ì—†",
                "ê°•ì˜ë¡ì—ì„œ ê´€ë ¨ ë‚´ìš©ì„ ì°¾ì„ ìˆ˜ ì—†"
            ]
            
            is_rejection = any(keyword in content for keyword in rejection_keywords)
            
            if not is_rejection:
                self._render_evidence_snippets(docs)
            else:
                st.info("ğŸ’¡ ê´€ë ¨ ë‚´ìš©ì´ ê°•ì˜ë¡ì— ì—†ì–´ ê·¼ê±° ìŠ¤ë‹ˆí«ì„ í‘œì‹œí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
    
    def run(self):
        """ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹¤í–‰"""
        # URL íŒŒë¼ë¯¸í„°ì—ì„œ Google OAuth ì½”ë“œ ìë™ ì²˜ë¦¬
        self._auto_handle_oauth_callback()
        
        # ì‚¬ì´ë“œë°” ë Œë”ë§
        vector_store, model, temp = self._render_sidebar()
        
        # ì§ˆì˜ì‘ë‹µ ì„¹ì…˜ ë Œë”ë§
        self._render_qa_section(vector_store, model, temp)
    
    def _auto_handle_oauth_callback(self):
        """OAuth ì½œë°±ì„ ìë™ìœ¼ë¡œ ì²˜ë¦¬"""
        query_params = st.query_params
        auth_code = query_params.get("code")
        
        if auth_code:
            # ì¸ì¦ ì½”ë“œê°€ URLì— ìˆìœ¼ë©´ ìë™ ì²˜ë¦¬
            st.info("ğŸ”„ Google Drive ì¸ì¦ì„ ì²˜ë¦¬í•˜ê³  ìˆìŠµë‹ˆë‹¤...")
            
            try:
                drive_client = GoogleDriveClient()
                if drive_client.complete_auth(auth_code):
                    st.success("âœ… Google Drive ì¸ì¦ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
                    st.info("ì´ì œ 'ğŸ“¥ êµ¬ê¸€ë“œë¼ì´ë¸Œì—ì„œ ê°•ì˜ë¡ ê°€ì ¸ì˜¤ê¸°' ë²„íŠ¼ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                    
                    # URL íŒŒë¼ë¯¸í„° ì œê±°í•˜ê³  ìƒˆë¡œê³ ì¹¨
                    st.query_params.clear()
                    st.rerun()
                else:
                    st.error("âŒ ì¸ì¦ ì²˜ë¦¬ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                    
            except Exception as e:
                st.error(f"âŒ ì¸ì¦ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                
            # URL íŒŒë¼ë¯¸í„° ì œê±°
            st.query_params.clear()


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    app = LectureRAGApp()
    app.run()


if __name__ == "__main__":
    main()